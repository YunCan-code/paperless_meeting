针对 “100人并发” 的场景，虽然听起来规模不大，但对于默认的开发环境配置（SQLite + 单进程 Python + 直接文件传输）来说，这确实是一个压力瓶颈，特别是在 文件下载 和 瞬间并发登录（比如会议开始前5分钟大家同时入会）的时刻。

以下是针对你当前代码库的具体优化方案，分为 后端（核心瓶颈） 和 安卓端（体验优化） 两部分。

第一部分：后端优化 (Backend) —— 解决“堵车”
目前的 backend 使用的是 SQLite 和 FastAPI 自带的静态文件服务，这是并发最大的短板。

1. 数据库迁移：抛弃 SQLite，拥抱 PostgreSQL/MySQL
现状： 代码中使用 sqlite3。SQLite 是文件级锁，100人同时写入（如签到、做笔记）会报错 Database is locked。 修改方案： 切换到 PostgreSQL（推荐）或 MySQL。

修改 backend/database.py：

Python

from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os

# 1. 修改数据库 URL
# 原来: SQLALCHEMY_DATABASE_URL = "sqlite:///./database.db"
# 现在 (示例): 使用 PostgreSQL (需安装 psycopg2-binary)
# 格式: postgresql://user:password@host:port/dbname
SQLALCHEMY_DATABASE_URL = os.getenv(
    "DATABASE_URL", 
    "postgresql://postgres:yourpassword@localhost:5432/paperless_meeting"
)

# 2. 修改 Engine 配置
# SQLite 需要 check_same_thread，PostgreSQL 不需要，但需要连接池配置
if "sqlite" in SQLALCHEMY_DATABASE_URL:
    engine = create_engine(
        SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False}
    )
else:
    # 生产环境连接池配置
    engine = create_engine(
        SQLALCHEMY_DATABASE_URL,
        pool_size=20,        # 保持连接数
        max_overflow=10,     # 最大溢出连接
        pool_timeout=30,     # 等待连接超时时间
        pool_recycle=1800    # 定期回收连接防止断连
    )

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()
2. 文件下载优化：Nginx 动静分离
现状： backend/main.py 使用 app.mount("/uploads", ...) 让 Python 负责传输文件。 风险： Python 的强项是逻辑计算，不是发文件。100人同时下载 50MB 的 PDF，会占用 Python 100个线程/协程，导致 API 接口卡死，无法登录。 修改方案： 使用 Nginx 挡在前面。

Nginx 配置示例 (nginx.conf)：

Nginx

server {
    listen 80;
    server_name your_server_ip;

    # 1. API 请求转发给 Python (FastAPI)
    location /api/ {
        proxy_pass http://127.0.0.1:8000/; 
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    # 2. 关键优化：静态文件直接由 Nginx 处理，不经过 Python
    # 假设你的文件存在 /app/backend/uploads
    location /uploads/ {
        alias /app/backend/uploads/; 
        expires 30d;          # 开启浏览器缓存
        sendfile on;          # 开启零拷贝高效传输
        tcp_nopush on;
    }
}
这样 Python 进程只处理几 KB 的 JSON 数据，几百兆的文件流量全部走 Nginx，互不影响。

3. 启动方式：使用多 Worker
不要用 python main.py 启动。使用 gunicorn 管理 uvicorn 工作进程。

生产环境启动命令：

Bash

# 启动 4 个工作进程 (建议数量 = CPU核数 * 2 + 1)
gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
第二部分：安卓端优化 (Android) —— 减少请求
对于 100 台设备，最容易把服务器压垮的不是“看”，而是“重复下载”。

1. 文件缓存机制 (File Caching)
现状： 我看你的 ReaderViewModel.kt，每次打开文件似乎都会触发下载。 优化： 下载前先检查本地是否已有该文件。

修改 ReaderViewModel.kt 中的 loadDocument：

Kotlin

// 修改 loadDocument 方法
fun loadDocument(downloadUrl: String, fileName: String) {
    viewModelScope.launch(Dispatchers.IO) {
        _uiState.value = ReaderUiState.Loading
        try {
            // 1. 定义本地存储路径 (建议使用 cacheDir 或 filesDir)
            val context = PaperlessApp.appContext // 需要获取全局 Context
            val file = File(context.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS), fileName)

            // 2. 检查文件是否存在且大小不为0
            if (file.exists() && file.length() > 0) {
                // -> 命中缓存，直接打开，不请求网络
                withContext(Dispatchers.Main) {
                    _uiState.value = ReaderUiState.Ready(file)
                }
                return@launch
            }

            // 3. 未命中缓存，执行下载 (Repository 需要支持将流写入 file)
            // ... 原有的下载逻辑 ...
            // 下载成功后，再次 load from file
        } catch (e: Exception) {
            // ...
        }
    }
}
这一步至关重要。会议中大家其实是在反复打开同一个文件，有了缓存，服务器压力瞬间减少 90%。

2. 网络超时与重试配置
在并发高时，网络响应会变慢。默认的超时时间可能太短导致报错。

修改 AppModule.kt 中的 OkHttp 配置：

Kotlin

@Provides
@Singleton
fun provideOkHttpClient(): OkHttpClient {
    return OkHttpClient.Builder()
        .connectTimeout(15, TimeUnit.SECONDS) // 连接超时
        .readTimeout(30, TimeUnit.SECONDS)    // 读取超时（下载大文件需要久一点）
        .writeTimeout(15, TimeUnit.SECONDS)
        // 自动重试机制
        .retryOnConnectionFailure(true) 
        .build()
}
3. 图片加载优化
会议列表如果有封面图，100人同时刷新列表会产生大量图片请求。 你的代码里用了 Coil (AsyncImage)，这是对的。Coil 默认自带内存缓存和磁盘缓存，这就足够了。确保不要禁用 Coil 的缓存功能。

总结清单
为了确保 100 人并发流畅，请按此顺序执行：

后端：把 sqlite3 换成 PostgreSQL (代码只需改两三行配置)。

后端：部署时配置 Nginx 负责 /uploads 路径的文件分发 (这是最大的性能提升点)。

后端：使用 gunicorn 开启 多 Worker 模式。

安卓端：实现 PDF 本地缓存判断，下载过的文件绝不下载第二次。

安卓端：适当调大 OkHttp 的 readTimeout，防止网络拥堵时客户端过早放弃。

做了这几点，支撑 100 人甚至 500 人并发都没有问题。